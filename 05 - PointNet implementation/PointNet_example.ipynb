{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PointNet example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C6tQkD062T-"
      },
      "source": [
        "%%capture\n",
        "!pip install open3d pytorch-lightning"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRc93NH0M8hT"
      },
      "source": [
        "Download and prepare a (very) small dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY6B25LH6FT1"
      },
      "source": [
        "!wget 'https://versaweb.dl.sourceforge.net/project/pointclouds/PCD%20datasets/hand_gestures.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR1AFRu3Hs7S"
      },
      "source": [
        "!unzip -q hand_gestures.zip\n",
        "!cp -r hand_gestures/ test/\n",
        "!cp -r test/ train/ \n",
        "!rm test/hand_{0..7}/image_{0002..0009}.pcd\n",
        "!rm train/hand_{0..7}/image_{0000..0001}.pcd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1nMUcUhNKXP"
      },
      "source": [
        "Inspect an example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egge5TMu7AO7"
      },
      "source": [
        "import numpy as np\n",
        "import open3d as o3d\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "def show_points(points, colors=None):\n",
        "\n",
        "    if colors is None:\n",
        "        colors = np.full((len(points),3),[0, 1, 0]) # fixed color\n",
        "\n",
        "    fig = go.Figure(\n",
        "        data=[\n",
        "            go.Scatter3d(\n",
        "                x=points[:,0], y=points[:,1], z=points[:,2], \n",
        "                mode='markers',\n",
        "                marker=dict(size=1, color=colors)\n",
        "            )\n",
        "        ],\n",
        "        layout=dict(\n",
        "            scene=dict(\n",
        "                xaxis=dict(visible=False),\n",
        "                yaxis=dict(visible=False),\n",
        "                zaxis=dict(visible=False)\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "    fig.show()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SjBEel67fo1"
      },
      "source": [
        "cloud = o3d.io.read_point_cloud(\"test/hand_1/image_0001.pcd\")\n",
        "\n",
        "show_points(np.asarray(cloud.points), colors=np.asarray(cloud.colors))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB98LD75_5rT"
      },
      "source": [
        "Create dataset module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-tXmyoC_-O0"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "from glob import glob\n",
        "import random\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root_dir, transform):\n",
        "        self.samples = sorted([y for y in glob(os.path.join(root_dir, '*', '*.pcd'))])\n",
        "        if not len(self.samples) > 0:\n",
        "            print(\"did not find any files\")\n",
        "        self.transform = transform\n",
        "\n",
        "    def load_sample(self, path):\n",
        "        cloud = o3d.io.read_point_cloud(path)\n",
        "        points = np.asarray(cloud.points)\n",
        "        cls = int(path.split('/')[1].split('_')[1])\n",
        "        cls = torch.nn.functional.one_hot(torch.as_tensor(cls), 8)\n",
        "        return points, cls\n",
        "\n",
        "    def sample_N_random(self,x,N=1024):\n",
        "        candiate_ids = [i for i in range(x.shape[0])]\n",
        "        sel = []\n",
        "        for _ in range(N):\n",
        "            # select idx\n",
        "            idx = random.randint(0,len(candiate_ids)-1)\n",
        "            sel.append(candiate_ids[idx])\n",
        "            # remove that idx from point_idx_options\n",
        "            del candiate_ids[idx]\n",
        "        return np.array(x[sel])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.load_sample(self.samples[idx])\n",
        "        x = self.sample_N_random(x)\n",
        "        #sample = {'input':x}\n",
        "        #if self.transform:\n",
        "        #    sample = self.transform(**sample)\n",
        "        #    x = sample['input']\n",
        "        return torch.as_tensor(x).float(), y.float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DOne3aiMrq9"
      },
      "source": [
        "Verify the output of the dataset module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqK3QfiOF29V"
      },
      "source": [
        "data_train = Dataset('train/',transform=None)\n",
        "x ,y = data_train[15]\n",
        "print(y)\n",
        "show_points(x.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHWDb0aY_-nI"
      },
      "source": [
        "Define PointNet and ClassHead"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q95px7tLACrr"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class PointNet(nn.Module):\n",
        "    def __init__(self, input_dims=3):\n",
        "        super(PointNet, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv1d(input_dims, 64, 1)\n",
        "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(1024)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(2, 1)\n",
        "        x = F.leaky_relu(self.bn1(self.conv1(x)),0.2)\n",
        "        x = F.leaky_relu(self.bn2(self.conv2(x)),0.2)\n",
        "        x = self.bn3(self.conv3(x))\n",
        "        x = torch.max(x, 2, keepdim=True)[0]\n",
        "        feat = x.view(-1, 1024)\n",
        "        return feat\n",
        "\n",
        "class ClassHead(nn.Module):\n",
        "    def __init__(self, input_dims=1024, output_dims=3, dropout_prob=0.5):\n",
        "        super(ClassHead, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dims, 256)\n",
        "        self.bn1 = nn.BatchNorm1d(256)\n",
        "        self.fc2 = nn.Linear(256, 64)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.fc3 = nn.Linear(64, output_dims)\n",
        "        self.do = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.bn1(self.do(self.fc1(x))),0.2)\n",
        "        x = F.leaky_relu(self.bn2(self.do(self.fc2(x))),0.2)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtPZKFflADTk"
      },
      "source": [
        "Build training module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6_wYqRTAIH5"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "class Classifier(pl.LightningModule):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.encoder = PointNet()\n",
        "        self.decoder = ClassHead(output_dims=cfg['n_classes'])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return Adam(self.parameters(), \n",
        "                    lr=self.cfg['lr'])\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        output = self(x)\n",
        "        loss = F.mse_loss(output, y)\n",
        "        self.log('loss', loss, on_step=True, prog_bar=False)\n",
        "        return {\"loss\": loss}\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        output = self(x)\n",
        "        loss = F.mse_loss(output, y)\n",
        "        return {\"val_loss\": loss}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
        "        self.log('avg_val_loss', avg_loss, on_epoch=True, prog_bar=True)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMhrAgYs01yh"
      },
      "source": [
        "Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHUdUvf805Rz"
      },
      "source": [
        "cfg = {\n",
        "        'experiment': 'hands',\n",
        "        'train_folder': 'train/',\n",
        "        'test_folder': 'test/',\n",
        "        'n_points': 1024,\n",
        "        'n_classes': 8,\n",
        "        'max_epoch': 300,\n",
        "        'gpus': 1,\n",
        "        'lr': 0.0005,\n",
        "        'batch_size': 16,\n",
        "        'device': 'cuda',\n",
        "      }"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzqHMgvDMh9p"
      },
      "source": [
        "Train a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRKo93NDAOiY"
      },
      "source": [
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer, loggers\n",
        "\n",
        "pl.seed_everything(42)\n",
        "logger = pl.loggers.TensorBoardLogger(os.path.join('lightning_logs/',cfg['experiment']))\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "train_dataloader = DataLoader(Dataset('train/',transform=None), batch_size=cfg['batch_size'], shuffle=True)\n",
        "val_dataloader = DataLoader(Dataset('test/',transform=None), batch_size=cfg['batch_size'], shuffle=False)\n",
        "\n",
        "model = Classifier(cfg)\n",
        "model.train()\n",
        "trainer = Trainer(gpus=cfg['gpus'], max_epochs=cfg['max_epoch'], logger=logger, deterministic=True)\n",
        "trainer.fit(model, train_dataloader=train_dataloader, val_dataloaders=val_dataloader)\n",
        "\n",
        "model_dir = os.path.join(\"trained_models/\",cfg['experiment'])\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "torch.save(model.encoder, os.path.join(model_dir,\"encoder.pt\"))\n",
        "torch.save(model.decoder, os.path.join(model_dir,\"decoder.pt\"))\n",
        "torch.save(model, os.path.join(model_dir,\"model.pt\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz09IbI0BllB"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir='lightning_logs/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4ReDlBq8eQH"
      },
      "source": [
        "Try the model. Given the small dataset and the lack of serious data augmentation performance is poor. (Check if the model has learned the training set?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeaBN1-L8e_n",
        "outputId": "da046d4a-fb95-465c-a201-183d5da97bfd"
      },
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    data_test = Dataset('test/',transform=None)\n",
        "    for sample in data_test:\n",
        "        x, y = sample\n",
        "        pred = model(torch.unsqueeze(x, 0))[0]\n",
        "        print(\"GT: {}, Pred {}\".format(torch.argmax(y, dim=0),torch.argmax(pred, dim=0)))\n",
        "        #show_points(x.numpy())"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GT: 0, Pred 6\n",
            "GT: 0, Pred 0\n",
            "GT: 1, Pred 6\n",
            "GT: 1, Pred 1\n",
            "GT: 2, Pred 6\n",
            "GT: 2, Pred 2\n",
            "GT: 3, Pred 6\n",
            "GT: 3, Pred 7\n",
            "GT: 4, Pred 6\n",
            "GT: 4, Pred 0\n",
            "GT: 5, Pred 6\n",
            "GT: 5, Pred 6\n",
            "GT: 6, Pred 6\n",
            "GT: 6, Pred 6\n",
            "GT: 7, Pred 6\n",
            "GT: 7, Pred 7\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}